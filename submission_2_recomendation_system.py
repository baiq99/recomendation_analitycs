# -*- coding: utf-8 -*-
"""Submission 2_Recomendation System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CYJRredc2ShxJXyC11BJxHul-7vlI18z

# Sistem Rekomendasi Wisata di Indonesia

- **Nama:** Baiq Ega Aulia
- **Email:** baiqusbypkp@gmail.com
- **ID Dicoding:** Baiq Ega Aulia

# Project Overview

Perkembangan teknologi membawa perubahan yang pesat, sehingga memungkinkan akses informasi menjadi lebih mudah. Salah satu sektor yang mengalami dampak dari perkembangan ini adalah pariwisata. Indonesia memiliki potensi wisata yang sangat luas dengan berbagai destinasi menarik yang tersedia. Namun, banyaknya pilihan sering kali membuat wisatawan kesulitan menentukan tujuan yang paling sesuai untuk dikunjungi. Oleh karena itu, diperlukan sistem rekomendasi yang dapat membantu wisatawan menemukan destinasi yang selaras dengan preferensi mereka. Proyek ini bertujuan untuk mengembangkan sistem rekomendasi destinasi wisata di Indonesia dengan menggunakan dataset yang memuat informasi rinci mengenai berbagai tempat wisata di negara ini.

Referensi: [Jurnal rekomendasi wisata](https://ejournal.unama.ac.id/index.php/jurnalmsi/article/download/1262/1071).

# Business Understanding

## Problem Statement

Berdasarkan latar belakang yang dijelaskan di atas, rumusan masalah yang didapatkan sebagai berikut:
1. Bagaimana sistem dapat merekomendasikan destinasi wisata di Indonesia berdasarkan deskripsi, kategori, dan fasilitas yang tersedia di dataset?
2. Bagaimana sistem dapat menyederhanakan proses pencarian informasi dan memberikan rekomendasi yang relevan secara efisien?

## Goals
Berdasarkan rumusan masalah yang dijelaskan di atas, tujuan dari projek ini adalah sebagai berikut:
1. Membangun sistem rekomendasi yang efektif menggunakan informasi deskripsi, kategori, dan fasilitas destinasi.
2. Membangun sistem rekomendasi yang efisien dan efektif menggunakan rating destinasi wisata.

## Solution
Berdasarkan tujuan di atas, ada beberapa solusi yang bisa dilakukan, yaitu:
1. Menerapkan Content-Based Filtering untuk merekomendasikan destinasi yang serupa dengan destinasi yang sebelumnya disukai oleh pengguna, berdasarkan deskripsi dan fitur destinasi tersebut (misalnya, kategori, fasilitas).
2. Menerapkan Collaborative Filtering untuk merekomendasikan destinasi berdasarkan preferensi pengguna lain yang memiliki selera yang mirip. Dalam konteks ini, gunakan user-item interaction untuk memprediksi rating yang mungkin diberikan user ke suatu destinasi.

# Data Understanding

## Deskripsi Dataset
Dataset pada projek ini diambil dari kaggle, yaitu [Sistem Rekomendasi Wisata](https://www.kaggle.com/datasets/aprabowo/indonesia-tourism-destination?select=tourism_with_id.csv). Pada dataset ini berisi 4 *file* dengan nama `package_tourism`, `tourism_rating`, `tourism_with_id`, dan `user` dengan ekstensi `csv` `(*Comma Separated Values*)`,dengan masing-masing banyaknya data yaitu 100 data dan 7 variabel untuk `package_tourism(package)`, 10000 data dan 3 variabel untuk `tourism_rating(rating)`, 437 data dan 13 variabel untuk `tourism_with_id(location)`, serta 300 data dan 3 variabel untuk `user`.
Berikut adalah penjelasan variabel dari masing-masing dataset:
### package_tourism(package)
Berikut merupakan deskripsi variabel dari dataset `package_tourism(package)`:
- Package: ID unik untuk setiap paket wisata.
- City: Kota di mana tempat wisata berada.
- Place_Tourism1 : Destinasi wisata pertama yang termasuk dalam paket
- Place_Tourism2 : Destinasi wisata kedua yang termasuk dalam paket
- Place_Tourism3 : Destinasi wisata ketiga yang termasuk dalam paket
- Place_Tourism4 : Destinasi wisata keempat yang termasuk dalam paket
- Place_Tourism5 : Destinasi wisata kelima yang termasuk dalam paket
### tourism_rating(rating)
Berikut merupakan deskripsi variabel dari dataset `tourism_rating(rating)`:
- User_Id       : ID unik untuk setiap user.
- Place_Id      : ID unik untuk setiap tempat wisata.
- Place_Ratings : Rating untuk setiap tempat wisata dari user.
### tourism_with_id(location)
- Place_Id      : ID unik untuk setiap tempat wisata.
- Place_Name    : Nama tempat wisata.
- Description   : Deskripsi singkat mengenai tempat wisata.
- Category      : Kategori tempat wisata (misalnya, Budaya, Taman Hiburan, Cagar Alam).
- City          : Kota di mana tempat wisata berada.
- Price         : Harga tiket masuk ke tempat wisata (dalam rupiah).
- Rating        : Penilaian rata-rata dari pengunjung (skala 1-5).
- Time_Minutes  : Waktu yang diperlukan untuk mengunjungi tempat wisata (dalam menit).
- Coordinate    : Koordinat geografis tempat wisata.
- Lat           : Garis lintang lokasi tempat wisata.
- Long          : Garis bujur lokasi tempat wisata.
- Unnamed: 11   : Tidak diketahui.
- Unnamed: 12   : Tidak diketahui.
### user
- User_Id       : ID unik untuk setiap pengguna.
- Location      : Kota atau lokasi asal pengguna.
- Age           : Usia pengguna.

## Import Libraray

Pada tahap ini, dilakukan import seluruh library python yang diperlukan dalam pengembangan projek
"""

#import library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

"""## Data Loading

Pada tahap, dilakukan pengabilan dataset. Dataset yang digunakan adalah Dataset Sistem Rekomendasi Wisata
"""

# definisi variabel untuk masing-masing dataset
package_df = pd.read_csv('package_tourism.csv')
rating_df = pd.read_csv('tourism_rating.csv')
location_df = pd.read_csv('tourism_with_id.csv')
user_df = pd.read_csv('user.csv')

print('Banyaknya data package: ', len(package_df))
print('Banyaknya data rating: ', len(rating_df))
print('Banyaknya data location: ', len(location_df))
print('Banyaknya data user: ', len(user_df))

"""Dataset destinasi wisata Indonesia terdiri dari empat sub-dataset, yaitu paket wisata, penilaian, lokasi, dan pengguna. Masing-masing sub-dataset memiliki jumlah data yang berbeda, yaitu 100 data untuk paket wisata, 10.000 data untuk penilaian, 437 data untuk lokasi, dan 300 data untuk pengguna.

## Exploratory Data Analysis

### Univariate EDA
Pada langkah ini, lakukan pengecekan banyaknya data dari masing-masing variabel serta beberapa nilai unik yang akan diidentifikasi.

#### Dataset package
Eksplorasi dataset package_tourism.csv yang berisi informasi paket wisata berdasarkan kota dan destinasi.
"""

package_df.head()

print('Banyak data: ', len(package_df['Package'].unique()))
print('Banyak Kota: ', package_df['City'].unique())

package_df.info()

feature = 'City'
count = package_df[feature].value_counts()
percent = 100*package_df[feature].value_counts(normalize=True)

df_vis = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_vis)
count.plot(kind='bar', title=feature);

"""Berikut adalah hasil variabel dalam dataset **package**:

- **Package**: Nomor identifikasi unik untuk setiap paket wisata.  
- **City**: Kota tempat destinasi wisata berada.  
- **Place_Tourism1**: Destinasi wisata pertama dalam paket.  
- **Place_Tourism2**: Destinasi wisata kedua dalam paket.  
- **Place_Tourism3**: Destinasi wisata ketiga dalam paket.  
- **Place_Tourism4**: Destinasi wisata keempat dalam paket.  
- **Place_Tourism5**: Destinasi wisata kelima dalam paket.  

Dataset **package** terdiri dari 100 entri dengan 7 variabel, di mana variabel **Place_tourism4** dan **Place_tourism5** mengandung nilai **null**. Selain itu, dataset ini mencakup 5 nilai unik pada variabel **City**, yaitu **Jakarta, Yogyakarta, Bandung, Semarang, dan Surabaya**, dengan masing-masing kota memiliki **20 paket wisata**.

#### Dataset Rating
Eksplorasi dataset tourism_rating.csv yang berisi informasi rating dari user terhadap tempat wisata tertentu.
"""

rating_df.head()

print('Banyak user: ', len(rating_df['User_Id'].unique()))
print('Banyak rating: ', (rating_df['Place_Ratings'].unique()))

rating_df.info()

feature = 'Place_Ratings'
count = rating_df[feature].value_counts()
percent = 100*rating_df[feature].value_counts(normalize=True)

df_vis = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_vis)
count.plot(kind='bar', title=feature);

"""Berikut adalah variabel dalam dataset **rating**:

- **User_Id**: Nomor identifikasi unik yang diberikan kepada setiap pengguna.  
- **Place_Id**: Nomor identifikasi unik yang digunakan untuk setiap destinasi wisata.  
- **Place_Ratings**: Penilaian yang diberikan oleh pengguna untuk setiap tempat wisata.  

Dataset **rating** terdiri dari **10.000 data** dengan **3 variabel**. Dalam dataset ini, terdapat **300 nilai unik** pada variabel **User_Id** serta **5 nilai unik** pada variabel **Place_Ratings**, yaitu **1, 2, 3, 4, dan 5**. Dari kelima nilai rating tersebut, rating **4** memiliki jumlah data tertinggi dibandingkan yang lain, meskipun selisihnya relatif kecil.

#### Dataset Location
Eksplorasi dataset tourism_with_id.csv yang memuat informasi detil tempat wisata, termasuk deskripsi dan kategori.
"""

location_df.head()

print('Banyak tempat wisata: ', len(location_df['Place_Name'].unique()))
print('Tipe Kategori: ', location_df['Category'].unique())

location_df.info()

feature = 'Category'
count = location_df[feature].value_counts()
percent = 100*location_df[feature].value_counts(normalize=True)

df_vis = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df_vis)
count.plot(kind='bar', title=feature);

"""Berikut adalah variabel dalam dataset **location**:

- **Place_Id**: Identifikasi unik untuk setiap destinasi wisata.  
- **Place_Name**: Nama dari tempat wisata tersebut.  
- **Description**: Ringkasan singkat yang menjelaskan tempat wisata.  
- **Category**: Jenis kategori destinasi wisata (contoh: Budaya, Taman Hiburan, Cagar Alam).  
- **City**: Kota tempat wisata berada.  
- **Price**: Biaya tiket masuk ke destinasi wisata (dalam rupiah).  
- **Rating**: Rata-rata penilaian dari pengunjung, dengan skala 1 hingga 5.  
- **Time_Minutes**: Perkiraan durasi kunjungan ke tempat wisata (dalam menit).  
- **Coordinate**: Koordinat geografis lokasi wisata.  
- **Lat**: Garis lintang dari lokasi wisata.  
- **Long**: Garis bujur dari lokasi wisata.  
- **Unnamed: 11**: Informasi tidak diketahui.  
- **Unnamed: 12**: Informasi tidak diketahui.  

Dataset **location** memiliki **437 data** dan terdiri dari **13 variabel**, mencerminkan jumlah unik destinasi wisata yang dicakup. Terdapat beberapa nilai **null** pada kolom **Time_Minutes** dan **Unnamed: 11**. Selain itu, dalam variabel **Category** terdapat **6 nilai unik**, yaitu **Budaya, Taman Hiburan, Cagar Alam, Bahari, Pusat Perbelanjaan, dan Tempat Ibadah**. Dari kategori tersebut, **Taman Hiburan** memiliki jumlah data tertinggi, yaitu **135 entri**.

#### Dataset User
Terakhir, eksplorasi dataset user.csv yang hanya berisi User_Id. Data ini dipakai untuk menyusun profil pengguna.
"""

user_df.head()

print('Banyak user: ', len(user_df['User_Id'].unique()))
print('Lokasi user: ', len(user_df['Location'].unique()))

user_df.info()

user_df.describe()

feature = 'Location'
count = user_df[feature].value_counts()
percent = 100*user_df[feature].value_counts(normalize=True)

top_5_count = count.head(5)
top_5_percent = percent.head(5)

df_vis = pd.DataFrame({'jumlah sampel':top_5_count, 'persentase':top_5_percent.round(1)})
print(df_vis)
top_5_count.plot(kind='bar', title=feature);

"""Berikut adalah variabel dalam dataset **user**:

- **User_Id**: Identifikasi unik untuk setiap pengguna.  
- **Location**: Kota atau daerah asal pengguna.  
- **Age**: Usia pengguna.  

Dataset **user** terdiri dari **300 data** dengan **3 variabel**, mencerminkan jumlah unik pengguna yang tercatat. Variabel **Location** memiliki **28 nilai unik**, menunjukkan beragam daerah asal pengguna. Selain itu, variabel **Age** mencakup rentang usia antara **24 hingga 40 tahun**. Sementara itu, **5 pengguna dengan jumlah rating terbanyak** berasal dari **Bekasi, Semarang, Yogyakarta, Lampung, dan Bogor**.

# Data Preparation

## Preprocessing untuk EDA

### Mengecek total user dan location
Pada tahap ini, empat dataset dibagi menjadi dua kelompok, yaitu **user** dan **location** (tempat wisata). Selanjutnya, dataset **rating_df** dan **user_df** digabungkan untuk memperoleh total jumlah pengguna, sedangkan dataset **location_df** dan **rating_df** digabungkan untuk menentukan total destinasi wisata.  

Selain itu, penggabungan dataset **user** dilakukan untuk menghitung jumlah keseluruhan pengguna yang terdaftar.
"""

# Menggabungkan seluruh userID
user_all = np.concatenate((
    rating_df['User_Id'].unique(),
    user_df['User_Id'].unique()
))

# Menghapus data yang sama kemudian mengurutkannya
user_all = np.sort(np.unique(user_all))

print('Jumlah seluruh user: ', len(user_all))

"""Jumlah total pengguna tercatat sebanyak 300 user.

Selanjutnya, dilakukan penggabungan dataset location untuk menentukan jumlah keseluruhan destinasi wisata yang ada.
"""

# Menggabungkan seluruh Place
place_all = np.concatenate((
    location_df['Place_Id'].unique(),
    rating_df['Place_Id'].unique()
))

# Menghapus data yang sama kemudian mengurutkannya
place_all = np.sort(np.unique(place_all))

print('Jumlah seluruh lokasi: ', len(place_all))

"""Jumlah total destinasi wisata yang tercatat dalam dataset location adalah 437 data.

### Mengecek jumlah rating
Langkah berikutnya adalah membuat variabel baru bernama **place** dengan menggabungkan data dari **rating_df** dan **location_df**. Tujuan dari penggabungan ini adalah untuk menganalisis jumlah rating berdasarkan data gabungan yang tersedia.
"""

place = pd.merge(rating_df, location_df , on='Place_Id', how='left')
place

place.info()

place.isnull().sum()

"""Dataset hasil gabungan rating_df dan location_df terdiri dari 10.000 data rating. Pada dataset ini, terdapat beberapa nilai null pada kolom time_minutes dan Unnamed: 11.

Selanjutnya, lakukan ekstraksi terhadap fitur numerik, kemudian hitung total dari fitur numerik tersebut berdasarkan Place-Id.
"""

# Pilih hanya kolom numerik
numerical_data = place.select_dtypes(include='number')

# Groupby 'Place-ID' dan hitung jumlahnya
result = numerical_data.groupby(place['Place_Id']).sum()
print(result)

"""## Data Preprocessing untuk *Content Based Filtering*

### Membuat Dataframe untuk Modeling Content-Based Filtering
Langkah berikutnya adalah membuat variabel baru bernama all_place_name, yang akan berisi data dari rating_df. Variabel ini kemudian akan digabungkan dengan beberapa kolom dari location_df, yaitu Place_Id, Place_Name, Category, dan City, berdasarkan Place-Id.
"""

all_place_name = rating_df
all_place_name

# Menggabungkan all resto_rate dengan dataframe geo berdasarkan placeID
all_place_name = pd.merge(all_place_name, location_df[['Place_Id','Place_Name', 'Category', 'City']], on='Place_Id', how='left')

# Print dataframe all_resto_name
all_place_name

"""### Memeriksa Nilai Null
Langkah selanjutnya adalah melakukan pengecekan terhadap nilai null, kemudian menganalisis deskripsi fitur numerik. Selain itu, dilakukan pemeriksaan terhadap jumlah data unik dalam kolom Place_Id, Place_Name, dan Category.

"""

all_place_name.isnull().sum()

"""### Memeriksa Data Duplikat
Langkah selanjutnya adalah melakukan pengecekan terhadap nilai duplikat dalam dataset untuk memastikan integritas dan keakuratan data yang digunakan.

"""

duplicate_rows = all_place_name.duplicated()

print(duplicate_rows.sum())

"""Karena terdapat data yang duplikat, langkah berikutnya adalah menghapus duplikasi tersebut untuk memastikan keakuratan dan kualitas dataset yang digunakan.

"""

all_place_name = all_place_name.drop_duplicates()

"""### Memeriksa Deskripsi Analisis dan Jumlah Data Unik
Pada tahap ini, dilakukan analisis deskriptif terhadap dataset serta pengecekan jumlah data unik pada kolom Place_Id, Place_Name, dan Location untuk memahami distribusi dan karakteristik data yang tersedia.

"""

all_place_name.describe()

len(all_place_name['Place_Id'].unique())

len(all_place_name['Place_Name'].unique())

len(all_place_name['Category'].unique())

"""Hasilnya, data telah dipastikan bersih dari **nilai null** dan memiliki **437 nilai unik** pada kolom **Place_Id** serta **Place_Name**. Selain itu, terdapat **6 nilai unik** pada **Category**. Dataset ini juga mencakup **300 pengguna** dengan rentang **rating** antara **1 hingga 5**.

### Memeriksa Kembali Data untuk Content-Based Filtering
Pada tahap ini, dilakukan pengecekan ulang terhadap data yang telah melalui proses preprocessing sebelumnya. Setelah itu, data akan diurutkan berdasarkan Place_Id untuk memastikan struktur yang sesuai dengan kebutuhan analisis lebih lanjut.
"""

all_place_name = all_place_name.sort_values('Place_Id', ascending=True)
all_place_name

"""### Memeriksa Nilai Unik pada Kolom Category
Langkah berikutnya adalah melakukan pengecekan terhadap nilai unik dalam kolom Category untuk memastikan keberagaman dan keberadaan berbagai kategori tempat wisata yang tersedia dalam dataset.

"""

all_place_name['Category'].unique()

"""Data dalam dataset memiliki berbagai kategori tempat wisata, yaitu Budaya, Taman Hiburan, Cagar Alam, Pusat Perbelanjaan, dan Tempat Ibadah.

### Menghapus Duplikasi pada Place_Id
Langkah berikutnya adalah membuat variabel preparation yang akan berisi data dari all_place_name. Setelah itu, data diurutkan berdasarkan Place_Id untuk memastikan struktur yang lebih terorganisir dan siap untuk analisis lebih lanjut.
"""

preparation = all_place_name
preparation.sort_values('Place_Id')

"""Selanjutnya, hapus nilai duplikat pada kolom Place_Id, karena hanya data yang bersifat unik yang akan digunakan dalam analisis.

"""

preparation = preparation.drop_duplicates('Place_Id')
preparation

"""Membuat Data Dictionary untuk Modeling
Langkah berikutnya adalah melakukan konversi data series menjadi list dengan menggunakan fungsi tolist() untuk mempermudah pemrosesan dan analisis lebih lanjut dalam proses modeling.

"""

# Mengonversi data series ‘placeID’ menjadi dalam bentuk list
place_id = preparation['Place_Id'].tolist()

# Mengonversi data series ‘Name’ menjadi dalam bentuk list
place_name = preparation['Place_Name'].tolist()

# Mengonversi data series ‘Rcuisine’ menjadi dalam bentuk list
place_cat = preparation['Category'].tolist()

print(len(place_id))
print(len(place_name))
print(len(place_cat))

"""Selanjutnya, buat data dictionary yang berisi informasi mengenai place_id, place_name, dan place_cat (kategori tempat wisata). Setelah itu, lakukan pengecekan untuk memastikan data telah dibuat dengan benar dan sesuai dengan kebutuhan analisis.

"""

place_new = pd.DataFrame({
    'id': place_id,
    'name': place_name,
    'category': place_cat
})

place_new

"""### Ekstraksi TF-IDF
Ekstraksi TF-IDF (Term Frequency-Inverse Document Frequency) adalah teknik yang digunakan untuk mengubah teks menjadi representasi numerik dengan mempertimbangkan seberapa sering suatu kata muncul dalam suatu dokumen dibandingkan dengan keseluruhan dokumen.

Pada langkah ini, buat variabel data yang berisi data place_new.
"""

data = place_new
data.head()

"""Panggil fungsi **TfidfVectorizer** dan lakukan **fit** terhadap kolom **Category**.  

"""

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data cuisine
tf.fit(data['category'])

# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names_out()

"""Lakukan **fit-transform** untuk mengubah data kategori menjadi vektor TF-IDF, kemudian periksa ukuran matriks hasil transformasi."""

tfidf_matrix = tf.fit_transform(data['category'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""Konversi data ke dalam bentuk **matriks** menggunakan fungsi **`todense()`** untuk mendapatkan representasi numerik dari TF-IDF.  """

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""Tampilkan hasil dari **TF-IDF**, di mana setiap kategori memiliki bobot tersendiri."""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=data.name
).sample(10, axis=1).sample(10, axis=0)

"""Sebagai contoh, **Museum Nike Ardilla** memiliki nilai **1** pada kategori **Budaya**, yang menandakan bahwa museum tersebut termasuk dalam kategori **Budaya**, dan konsep ini berlaku untuk destinasi lainnya.

## Data Preprocessing untuk Collaborative Filtering

### Membuat Dataframe untuk Modeling Collaborative Filtering
Langkah pertama dalam proses ini adalah membuat variabel df yang berisi dataset rating_df, yang akan digunakan sebagai dasar dalam penerapan metode Collaborative Filtering.
"""

df = rating_df
df

"""Selanjutnya, lakukan persiapan data dengan menyandikan (encoding) fitur User_Id ke dalam indeks berbentuk integer untuk memastikan data dapat digunakan dalam proses pemodelan lebih lanjut.

"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df['User_Id'].unique().tolist()
print('list userID: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

"""Selanjutnya, lakukan persiapan data dengan menyandikan (encoding) fitur Place_Id ke dalam indeks berbentuk integer, sehingga data dapat digunakan secara optimal dalam proses pemodelan lebih lanjut.

"""

# Mengubah placeID menjadi list tanpa nilai yang sama
place_ids = df['Place_Id'].unique().tolist()

# Melakukan proses encoding placeID
place_to_place_encoded = {x: i for i, x in enumerate(place_ids)}

# Melakukan proses encoding angka ke placeID
place_encoded_to_place = {i: x for i, x in enumerate(place_ids)}

"""Langkah berikutnya adalah memetakan User_Id dan Place_Id ke dalam dataframe yang sesuai, sehingga setiap pengguna dan destinasi wisata memiliki relasi yang jelas dalam dataset.

"""

# Mapping userID ke dataframe user
df['user'] = df['User_Id'].map(user_to_user_encoded)

# Mapping placeID ke dataframe place
df['place'] = df['Place_Id'].map(place_to_place_encoded)

"""Langkah berikutnya adalah melakukan **pemeriksaan** terhadap beberapa aspek dalam data, seperti:  

- **Jumlah pengguna** dalam dataset.  
- **Jumlah destinasi wisata** yang tersedia.  
- **Mengonversi nilai rating** ke tipe data **float** untuk memastikan kompatibilitas dengan analisis lebih lanjut.  

"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah place
num_place = len(place_encoded_to_place)
print(num_place)

# Mengubah rating menjadi nilai float
df['Place_Ratings'] = df['Place_Ratings'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(df['Place_Ratings'])

# Nilai maksimal rating
max_rating = max(df['Place_Ratings'])

print('Number of User: {}, Number of place: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_place, min_rating, max_rating
))

"""Dataframe menunjukkan bahwa terdapat 300 pengguna, 437 destinasi wisata, serta nilai rating yang berkisar antara 1.0 hingga 5.0.

### Mengacak Data
Langkah berikutnya adalah mengacak data untuk memastikan distribusinya menjadi random, sehingga model dapat belajar dari berbagai pola tanpa bias terhadap urutan asli data.
"""

df = df.sample(frac=1, random_state=42)
df

"""Karena kolom User_Id belum mengalami pengacakan, langkah berikutnya adalah mengacak kolom user terlebih dahulu untuk memastikan distribusi data menjadi lebih acak dan tidak terurut secara default.

"""

df['user'] = np.random.permutation(df['user'].values)
df

"""### Membagi Data Train dan Data Validation
Langkah berikutnya adalah membagi data train dan data validasi dengan komposisi 80:20 dari data yang telah melalui tahap data preparation.
Sebelum melakukan pembagian, lakukan pemetaan (mapping) data user dan place agar setiap nilai pengguna dan tempat wisata direpresentasikan sebagai satu value. Selain itu, ubah rating ke dalam skala 0 sampai 1 untuk mempermudah proses training model.

"""

# Membuat variabel x untuk mencocokkan data user dan resto menjadi satu value
x = df[['user', 'place']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""# Modeling and Result
Proses modeling yang dilakukan pada proyek ini adalah dengan membuat algoritma machine learning, yaitu content based filtering dan collabrative filtering.

### 1. Model Development dengan Content Based Filtering

Langkah pertama adalah menghitung derajat kesamaan antar tempat wisata dengan menggunakan teknik Cosine Similarity. Metode ini digunakan untuk mengukur tingkat kemiripan antar destinasi wisata berdasarkan fitur yang tersedia.
"""

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Selanjutnya, periksa matriks kesamaan antar tempat wisata dengan menampilkan nama tempat wisata dalam 5 sampel kolom (axis = 1) dan 10 sampel baris (axis = 0).
Langkah ini membantu memahami bagaimana setiap destinasi wisata berhubungan berdasarkan derajat kesamaannya dalam dataset.

"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['name'], columns=data['name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap lokasi
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Dalam contoh tersebut, terlihat bahwa Kampung Cina memiliki nilai 1 dengan Kelnteng Sanggar Agung dan Monumen Batik Yogyakarta, yang menunjukkan bahwa ketiganya termasuk dalam kategori yang sama.

#### Modeling Content-Based Filtering
Langkah selanjutnya adalah membuat fungsi rekomendasi tempat wisata berdasarkan data yang telah dipersiapkan dalam proses data preparation. Dalam fungsi ini, sistem akan memberikan 5 rekomendasi tempat wisata berdasarkan nama destinasi yang diinputkan.
"""

def location_recommendations(nama, similarity_data=cosine_sim_df, items=data[['name', 'category']], k=5):
    """
    Rekomendasi Resto berdasarkan kemiripan dataframe

    Parameter:
    ---
    nama : tipe data string (str)
                Nama Tempat Wisata (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan resto sebagai
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---


    Pada index ini akan diambil k dengan nilai similarity terbesar
    pada index matrix yang diberikan (i).
    """


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""Selanjutnya, masukkan data yang ingin dicari rekomendasinya, sehingga sistem dapat memberikan hasil rekomendasi tempat wisata berdasarkan analisis Content-Based Filtering.

"""

data[data.name.eq('Kebun Binatang Ragunan')]

"""Selanjutnya, gunakan fungsi yang telah dibuat sebelumnya untuk mencari rekomendasi tempat wisata.

"""

location_recommendations('Kebun Binatang Ragunan')

"""Hasilnya menunjukkan bahwa sistem merekomendasikan destinasi wisata dengan kategori yang sama, sehingga pengguna mendapatkan pilihan tempat yang relevan sesuai dengan preferensinya.

### 2. Model Development dengan Collaborative Filtering

Buat class RecommenderNet dengan menggunakan Keras Model class untuk mengembangkan sistem rekomendasi berbasis Collaborative Filtering.
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_place, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_place = num_place
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-4)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.place_embedding = layers.Embedding( # layer embeddings place
        num_place,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.place_bias = layers.Embedding(num_place, 1) # layer embedding place bias

    self.dropout = layers.Dropout(0.3)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_vector = self.dropout(user_vector)
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    place_vector = self.place_embedding(inputs[:, 1]) # memanggil layer embedding 3
    place_vector = self.dropout(place_vector)
    place_bias = self.place_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_place = tf.tensordot(user_vector, place_vector, 2)

    x = dot_user_place + user_bias + place_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""Setelah itu, lakukan compile terhadap model dengan mengatur:
- Loss function menggunakan binary crossentropy
- Optimizer menggunakan Adam
- Metrik evaluasi menggunakan RMSE (Root Mean Square Error)

"""

model = RecommenderNet(num_users, num_place, 20) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Selanjutnya, lakukan proses training pada model dengan data yang telah dipersiapkan."""

# Memulai training
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""Selanjutnya, lakukan visualisasi proses training dengan menggunakan Matplotlib untuk memplot metrik evaluasi, sehingga dapat melihat bagaimana performa model selama proses pelatihan dan memahami tren yang terjadi.

"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Berdasarkan grafik tersebut, didapatkan bahwa RMSE dari data train adalah 0.3144 dan RMSE dari data validation adalah 0.3661, dimana sistem yang dikembangkan sudah baik untuk model Collaborative Filtering ini.

Sebelum menjalankan prediksi sistem rekomendasi, terlebih dahulu buat variabel place_not_visited yang berisi daftar destinasi yang belum dikunjungi oleh pengguna. Daftar ini akan digunakan sebagai dasar dalam memberikan rekomendasi tempat wisata yang sesuai.
"""

place_df = place_new
df = pd.read_csv('tourism_rating.csv')

# Mengambil sample user
user_id = df['User_Id'].sample(1).iloc[0]
place_visited_by_user = df[df['User_Id'] == user_id]

# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
place_not_visited = place_df[~place_df['id'].isin(place_visited_by_user['Place_Id'].values)]['id']
place_not_visited = list(
    set(place_not_visited)
    .intersection(set(place_to_place_encoded.keys()))
)

place_not_visited = [[place_to_place_encoded.get(x)] for x in place_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_place_array = np.hstack(
    ([[user_encoder]] * len(place_not_visited), place_not_visited)
)

"""Langkah berikutnya adalah melakukan prediksi untuk mendapatkan 10 rekomendasi tempat wisata berdasarkan data yang telah diproses sebelumnya. Sistem akan menganalisis pola preferensi pengguna dan memberikan rekomendasi yang paling sesuai.

"""

ratings = model.predict(user_place_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_place_ids = [
    place_encoded_to_place.get(place_not_visited[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('place with high ratings from user')
print('----' * 8)

top_place_user = (
    place_visited_by_user.sort_values(
        by = 'Place_Ratings',
        ascending=False
    )
    .head(5)['Place_Ratings'].values
)

place_df_rows = place_df[place_df['id'].isin(top_place_user)]
for row in place_df_rows.itertuples():
    print(row.name, ':', row.category)

print('----' * 8)
print('Top 10 place recommendation')
print('----' * 8)

recommended_place = place_df[place_df['id'].isin(recommended_place_ids)]
for row in recommended_place.itertuples():
    print(row.name, ':', row.category)

"""# Kesimpulan

Proyek ini berhasil mengembangkan **sistem rekomendasi tempat wisata** menggunakan dua pendekatan utama: *Content-Based Filtering* dan *Collaborative Filtering*.  

Selama proses pengerjaan, berbagai tahapan telah dilakukan, termasuk **Data Understanding, Data Preparation, Modeling**, serta **Evaluasi Model** untuk memastikan sistem bekerja secara optimal.  

Pada pendekatan **Content-Based Filtering**, hasil evaluasi menunjukkan performa yang sangat baik, sehingga sistem berhasil memberikan rekomendasi yang akurat berdasarkan informasi **deskripsi, kategori, dan fasilitas destinasi wisata**.  

Sementara itu, dalam **Collaborative Filtering**, hasil evaluasi juga cukup baik, sehingga sistem rekomendasi dapat bekerja secara efisien dengan memanfaatkan **rating destinasi wisata** untuk memberikan rekomendasi yang relevan.  

Namun, proyek ini masih memiliki keterbatasan karena ukuran dataset yang terbatas. Hal ini menyebabkan kemungkinan model memberikan rekomendasi yang kurang sesuai dengan input yang diberikan pengguna.  

"""